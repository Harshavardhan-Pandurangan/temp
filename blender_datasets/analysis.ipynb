{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install rosbags opencv-python numpy matplotlib cv_bridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<rosbags.highlevel.anyreader.AnyReader object at 0x77f1941fd610>\n",
      "Opened bag file for reading\n",
      "\n",
      "Topics in the bag file:\n",
      "/tf_static geometry_msgs/msg/TransformStamped\n",
      "/camera/color/camera_info sensor_msgs/msg/CameraInfo\n",
      "/camera/depth/image_rect_raw sensor_msgs/msg/Image\n",
      "/camera/color/image_raw sensor_msgs/msg/Image\n",
      "\n",
      "Duration of the bag file: 127966666753\n",
      "\n",
      "No. of messages in the bag file: 11522\n",
      "\n",
      "Messages in the bag file:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'connections' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 37\u001b[0m\n\u001b[1;32m     35\u001b[0m count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# Iterate over messages.\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m connection, timestamp, rawdata \u001b[38;5;129;01min\u001b[39;00m reader\u001b[38;5;241m.\u001b[39mmessages(connections\u001b[38;5;241m=\u001b[39m\u001b[43mconnections\u001b[49m):\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;66;03m# get the image message\u001b[39;00m\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m connection\u001b[38;5;241m.\u001b[39mtopic \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/tf\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     40\u001b[0m         \u001b[38;5;66;03m# plot the image\u001b[39;00m\n\u001b[1;32m     41\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mImg no\u001b[39m\u001b[38;5;124m'\u001b[39m, count)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'connections' is not defined"
     ]
    }
   ],
   "source": [
    "from rosbags.rosbag1 import Reader\n",
    "from rosbags.highlevel import AnyReader\n",
    "from rosbags.typesys import Stores, get_typestore\n",
    "from rosbags.typesys.stores.ros1_noetic import sensor_msgs__msg__Image as Image\n",
    "from rosbags.serde import deserialize_cdr\n",
    "import time\n",
    "from pathlib import Path\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "bag_path = 'rrc2.bag'\n",
    "bag_path = 'output.bag'\n",
    "\n",
    "# Create reader instance and open for reading.\n",
    "with AnyReader([Path(bag_path)]) as reader:\n",
    "    print(reader)\n",
    "    print('Opened bag file for reading')\n",
    "\n",
    "    print('\\nTopics in the bag file:')\n",
    "    # Topic and msgtype information is available on .connections list.\n",
    "    for connection in reader.connections:\n",
    "        print(connection.topic, connection.msgtype)\n",
    "\n",
    "    # print the duration of the bag file\n",
    "    print('\\nDuration of the bag file:', reader.duration)\n",
    "\n",
    "    print('\\nNo. of messages in the bag file:', reader.message_count)\n",
    "\n",
    "    # reduce only to the image messages\n",
    "    connections = []\n",
    "    for connection in reader.connections:\n",
    "        if connection.topic == '/tf':\n",
    "            connections = [connection]\n",
    "\n",
    "    print('\\nMessages in the bag file:')\n",
    "    count = 1\n",
    "    # Iterate over messages.\n",
    "    for connection, timestamp, rawdata in reader.messages(connections=connections):\n",
    "        # get the image message\n",
    "        if connection.topic == '/tf':\n",
    "            # plot the image\n",
    "            print('\\nImg no', count)\n",
    "            print('image', timestamp)\n",
    "            print('connection', connection)\n",
    "            print('msgtype', connection.msgtype)\n",
    "\n",
    "            # print('rawdata', rawdata)\n",
    "\n",
    "            # deserialize the message\n",
    "            print(len(rawdata))\n",
    "            img = reader.deserialize(rawdata, connection.msgtype)\n",
    "\n",
    "            print(img)\n",
    "\n",
    "            # show the image\n",
    "            # reshape the image\n",
    "            # img_data = img.data.reshape(img.height, img.width, 3)\n",
    "            # plt.imshow(img_data)\n",
    "\n",
    "            # save the images with the count as the name\n",
    "            # plt.savefig(f'./images/{count}.png')\n",
    "            # img_data = cv2.cvtColor(img_data, cv2.COLOR_RGB2BGR)\n",
    "            # cv2.imwrite(f'./images/{count}.png', img_data)\n",
    "\n",
    "            count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert all the images to a video\n",
    "image_folder = './images/'\n",
    "video_name = 'video.avi'\n",
    "\n",
    "images_paths = Path(image_folder).glob('*.png')\n",
    "# sort the images\n",
    "images_paths = sorted(images_paths, key=lambda x: int(x.stem))\n",
    "\n",
    "images = [img for img in images_paths]\n",
    "frame = cv2.imread(str(images[0]))\n",
    "height, width, layers = frame.shape\n",
    "\n",
    "video = cv2.VideoWriter(video_name, 0, 30, (width, height))\n",
    "\n",
    "for image in images:\n",
    "    video.write(cv2.imread(str(image)))\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "video.release()\n",
    "print('Video created successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's do all this to the depth image\n",
    "# reduce only to the image messages\n",
    "\n",
    "with AnyReader([Path(bag_path)]) as reader:\n",
    "    print(reader)\n",
    "    print('Opened bag file for reading')\n",
    "\n",
    "    print('\\nTopics in the bag file:')\n",
    "    # Topic and msgtype information is available on .connections list.\n",
    "    for connection in reader.connections:\n",
    "        print(connection.topic, connection.msgtype)\n",
    "\n",
    "    print('\\nNo. of messages in the bag file:', reader.message_count)\n",
    "\n",
    "    # reduce only to the image messages\n",
    "    for connection in reader.connections:\n",
    "        if connection.topic == '/camera/depth/image_rect_raw':\n",
    "            connections = [connection]\n",
    "\n",
    "    print('\\nMessages in the bag file:')\n",
    "    count = 1\n",
    "    # Iterate over messages.\n",
    "    for connection, timestamp, rawdata in reader.messages(connections=connections):\n",
    "        # get the image message\n",
    "        if connection.topic == '/camera/depth/image_rect_raw':\n",
    "            # plot the image\n",
    "            print('\\nImg no', count)\n",
    "            # print('image', timestamp)\n",
    "            # print('connection', connection)\n",
    "            # print('msgtype', connection.msgtype)\n",
    "\n",
    "            # deserialize the message\n",
    "            print(len(rawdata))\n",
    "            img = reader.deserialize(rawdata, connection.msgtype)\n",
    "\n",
    "            print(img)\n",
    "\n",
    "            # show the image\n",
    "            # reshape the image\n",
    "            img_data = img.data.reshape(img.height, img.width, 2)\n",
    "\n",
    "            # convert the image form 2 channels to 1 channel\n",
    "            img_data = (img_data[:,:,1].astype(np.uint16) << 8) | img_data[:,:,0]\n",
    "            # img_data = img_data[:, :, 1]\n",
    "            # print(img_data)\n",
    "            # plt.imshow(img_data)\n",
    "\n",
    "            # save the images with the count as the name\n",
    "            # plt.savefig(f'./images/{count}.png')\n",
    "            img_data = cv2.cvtColor(img_data, cv2.COLOR_GRAY2BGR)\n",
    "            cv2.imwrite(f'./depth_images/{count}.png', img_data)\n",
    "\n",
    "            count += 1\n",
    "\n",
    "# convert all the images to a video\n",
    "image_folder = './depth_images/'\n",
    "video_name = 'depth_video.avi'\n",
    "\n",
    "images_paths = Path(image_folder).glob('*.png')\n",
    "# sort the images\n",
    "images_paths = sorted(images_paths, key=lambda x: int(x.stem))\n",
    "\n",
    "images = [img for img in images_paths]\n",
    "frame = cv2.imread(str(images[0]))\n",
    "height, width, layers = frame.shape\n",
    "\n",
    "video = cv2.VideoWriter(video_name, 0, 30, (width, height))\n",
    "\n",
    "for image in images:\n",
    "    video.write(cv2.imread(str(image)))\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "video.release()\n",
    "print('Depth Video created successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rosbags.rosbag1 import Reader\n",
    "from rosbags.highlevel import AnyReader\n",
    "from rosbags.typesys import Stores, get_typestore\n",
    "from rosbags.typesys.stores.ros1_noetic import sensor_msgs__msg__CompressedImage as CompressedImage\n",
    "from rosbags.serde import deserialize_cdr\n",
    "import time\n",
    "from pathlib import Path\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# open and analyse a new bag file\n",
    "bag_path = './output.bag'\n",
    "\n",
    "# Create reader instance and open for reading.\n",
    "with AnyReader([Path(bag_path)]) as reader:\n",
    "    print(reader)\n",
    "    print('Opened bag file for reading')\n",
    "\n",
    "    print('\\nTopics in the bag file:')\n",
    "    # Topic and msgtype information is available on .connections list.\n",
    "    for connection in reader.connections:\n",
    "        print(connection.topic, connection.msgtype)\n",
    "\n",
    "    print('\\nNo. of messages in the bag file:', reader.message_count)\n",
    "\n",
    "    # print the duration of the bag file\n",
    "    print('\\nDuration of the bag file:', reader.duration)\n",
    "\n",
    "    # reduce only to the image messages\n",
    "    for connection in reader.connections:\n",
    "        if connection.topic == '/camera/color/image_raw':\n",
    "            connections = [connection]\n",
    "\n",
    "    print('\\nMessages in the bag file:')\n",
    "    count = 1\n",
    "    # Iterate over messages.\n",
    "    count = 1\n",
    "    for connection, timestamp, rawdata in reader.messages(connections=connections):\n",
    "        # get the image message\n",
    "        if connection.topic == '/camera/color/image_raw':\n",
    "            # plot the image\n",
    "            print('\\nImg no', count)\n",
    "            print('image', timestamp)\n",
    "            print('connection', connection)\n",
    "            print('msgtype', connection.msgtype)\n",
    "\n",
    "            # deserialize the message\n",
    "            print(len(rawdata))\n",
    "            img = reader.deserialize(rawdata, connection.msgtype)\n",
    "\n",
    "            print(img)\n",
    "\n",
    "            # show the image\n",
    "            # reshape the image\n",
    "            img_data = cv2.imdecode(np.frombuffer(img.data, np.uint8), cv2.IMREAD_COLOR)\n",
    "            plt.imshow(img_data)\n",
    "\n",
    "            # save the images with the count as the name\n",
    "            # plt.savefig(f'./images/{count}.png')\n",
    "            # cv2.imwrite(f'./compressed_images/{count}.png', img_data)\n",
    "\n",
    "            if count > 10:\n",
    "                break\n",
    "            count += 1\n",
    "\n",
    "# 179672400326\n",
    "# 157133333249"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rosbags.highlevel import AnyReader\n",
    "from pathlib import Path\n",
    "\n",
    "def inspect_bag(bagfile_path):\n",
    "    with AnyReader([Path(bagfile_path)]) as reader:\n",
    "        for connection, timestamp, rawdata in reader.messages():\n",
    "            if 'image' in connection.topic:\n",
    "                msg = reader.deserialize(rawdata, connection.msgtype)\n",
    "                print(f\"Topic: {connection.topic}\")\n",
    "                print(f\"Message type: {connection.msgtype}\")\n",
    "                if hasattr(msg, 'data'):\n",
    "                    print(f\"Data type: {type(msg.data)}\")\n",
    "                    print(f\"Data length: {len(msg.data)}\")\n",
    "                    print(f\"Image dimensions: {msg.height}x{msg.width}\")\n",
    "                    print(f\"Expected size: {msg.height * msg.width * 3}\")\n",
    "                break\n",
    "\n",
    "bagfile_path = './output.bag'\n",
    "inspect_bag(bagfile_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inspect_bag(bagfile_path):\n",
    "    with AnyReader([Path(bagfile_path)]) as reader:\n",
    "        for connection, timestamp, rawdata in reader.messages():\n",
    "            if 'image' in connection.topic:\n",
    "                msg = reader.deserialize(rawdata, connection.msgtype)\n",
    "                print(f\"Topic: {connection.topic}\")\n",
    "                print(f\"Message type: {connection.msgtype}\")\n",
    "                if hasattr(msg, 'data'):\n",
    "                    print(f\"Data type: {type(msg.data)}\")\n",
    "                    print(f\"Data length: {len(msg.data)}\")\n",
    "                    print(f\"Image dimensions: {msg.height}x{msg.width}\")\n",
    "                    print(f\"Expected size: {msg.height * msg.width * 3}\")\n",
    "                    print(f\"Data min/max: {msg.data.min()}/{msg.data.max()}\")  # Check data range\n",
    "                    print(f\"Data dtype: {msg.data.dtype}\")  # Check data type\n",
    "                break\n",
    "\n",
    "bagfile_path = './rrc2.bag'\n",
    "inspect_bag(bagfile_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_written_image(bagfile_path):\n",
    "    with AnyReader([Path(bagfile_path)]) as reader:\n",
    "        for connection, timestamp, rawdata in reader.messages():\n",
    "            if 'image' in connection.topic:\n",
    "                msg = reader.deserialize(rawdata, connection.msgtype)\n",
    "                # Reshape the data back to an image\n",
    "                img_array = msg.data.reshape(msg.height, msg.width, 3)\n",
    "                # Save it to verify visually\n",
    "                cv2.imwrite('verify_image.jpg', img_array)\n",
    "                break\n",
    "\n",
    "# Try this on your output bag\n",
    "verify_written_image('output.bag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_depth_bag(bagfile_path):\n",
    "    \"\"\"Verify the contents of the created bag file.\"\"\"\n",
    "    from rosbags.highlevel import AnyReader\n",
    "\n",
    "    with AnyReader([Path(bagfile_path)]) as reader:\n",
    "        for connection, timestamp, rawdata in reader.messages():\n",
    "            if 'depth' in connection.topic:\n",
    "                msg = reader.deserialize(rawdata, connection.msgtype)\n",
    "                print(f\"Topic: {connection.topic}\")\n",
    "                print(f\"Message type: {connection.msgtype}\")\n",
    "                print(f\"Data type: {type(msg.data)}\")\n",
    "                print(f\"Data length: {len(msg.data)}\")\n",
    "                print(f\"Image dimensions: {msg.height}x{msg.width}\")\n",
    "                print(f\"Encoding: {msg.encoding}\")\n",
    "                print(f\"Step: {msg.step}\")\n",
    "                print(f\"Data dtype: {msg.data.dtype}\")\n",
    "\n",
    "                # Reshape and save first image to verify\n",
    "                depth_img = msg.data.reshape(msg.height, msg.width)\n",
    "                cv2.imwrite('verify_depth.png', depth_img)\n",
    "                break\n",
    "\n",
    "verify_depth_bag('output.bag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the rr2.bag file and read the camera info\n",
    "from rosbags.rosbag1 import Reader\n",
    "from rosbags.highlevel import AnyReader\n",
    "from rosbags.typesys import Stores, get_typestore\n",
    "from rosbags.typesys.stores.ros1_noetic import sensor_msgs__msg__Image as Image\n",
    "from rosbags.serde import deserialize_cdr\n",
    "import time\n",
    "from pathlib import Path\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "bag_path = './output.bag'\n",
    "\n",
    "# Create reader instance and open for reading.\n",
    "with AnyReader([Path(bag_path)]) as reader:\n",
    "    print(reader)\n",
    "    print('Opened bag file for reading')\n",
    "\n",
    "    print('\\nTopics in the bag file:')\n",
    "    # Topic and msgtype information is available on .connections list.\n",
    "    for connection in reader.connections:\n",
    "        print(connection.topic, connection.msgtype)\n",
    "\n",
    "    # print the duration of the bag file\n",
    "    print('\\nDuration of the bag file:', reader.duration)\n",
    "\n",
    "    print('\\nNo. of messages in the bag file:', reader.message_count)\n",
    "\n",
    "    # reduce only to the image messages\n",
    "    for connection in reader.connections:\n",
    "        if connection.topic == '/camera/color/camera_info':\n",
    "            connections = [connection]\n",
    "\n",
    "    print('\\nMessages in the bag file:')\n",
    "    count = 1\n",
    "    # Iterate over messages.\n",
    "    for connection, timestamp, rawdata in reader.messages(connections=connections):\n",
    "        # get the image message\n",
    "        if connection.topic == '/camera/color/camera_info':\n",
    "            # plot the image\n",
    "            print('\\nImg no', count)\n",
    "            print('image', timestamp)\n",
    "            print('connection', connection)\n",
    "            print('msgtype', connection.msgtype)\n",
    "\n",
    "            # deserialize the message\n",
    "            print(len(rawdata))\n",
    "            img = reader.deserialize(rawdata, connection.msgtype)\n",
    "\n",
    "            print(img)\n",
    "\n",
    "            count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bpy\n",
    "import numpy as np\n",
    "from mathutils import Matrix\n",
    "from rosbags.rosbag1 import Writer\n",
    "from rosbags.typesys.types import sensor_msgs__msg__CameraInfo\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "def get_blender_camera_info(camera_obj=None):\n",
    "    \"\"\"Extract camera parameters from Blender camera.\"\"\"\n",
    "    if camera_obj is None:\n",
    "        # Get the active camera if none specified\n",
    "        camera_obj = bpy.context.scene.camera\n",
    "\n",
    "    if camera_obj is None or camera_obj.type != 'CAMERA':\n",
    "        raise ValueError(\"No valid camera found\")\n",
    "\n",
    "    scene = bpy.context.scene\n",
    "    render = scene.render\n",
    "\n",
    "    # Get render resolution\n",
    "    width = render.resolution_x\n",
    "    height = render.resolution_y\n",
    "\n",
    "    # Get camera data\n",
    "    cam_data = camera_obj.data\n",
    "\n",
    "    # Calculate focal length in pixels\n",
    "    # Blender's sensor width is in mm, focal length is in mm\n",
    "    sensor_width_in_mm = cam_data.sensor_width\n",
    "    focal_length_mm = cam_data.lens\n",
    "\n",
    "    # Convert focal length to pixels\n",
    "    focal_length_pixels = (focal_length_mm / sensor_width_in_mm) * width\n",
    "\n",
    "    # Calculate optical center (assuming centered principal point)\n",
    "    cx = width / 2\n",
    "    cy = height / 2\n",
    "\n",
    "    # Create camera intrinsic matrix K\n",
    "    K = [\n",
    "        focal_length_pixels, 0, cx,\n",
    "        0, focal_length_pixels, cy,\n",
    "        0, 0, 1\n",
    "    ]\n",
    "\n",
    "    # Get camera extrinsics (world to camera transform)\n",
    "    camera_matrix_world = camera_obj.matrix_world\n",
    "\n",
    "    # Convert from Blender's coordinate system to ROS coordinate system\n",
    "    # Blender: Y forward, X right, Z up\n",
    "    # ROS: X forward, Y left, Z up\n",
    "    coord_transform = Matrix([\n",
    "        [0, -1, 0, 0],\n",
    "        [0, 0, -1, 0],\n",
    "        [1, 0, 0, 0],\n",
    "        [0, 0, 0, 1]\n",
    "    ])\n",
    "\n",
    "    # Calculate transformation matrix\n",
    "    transform_matrix = coord_transform @ camera_matrix_world\n",
    "\n",
    "    # Extract rotation matrix\n",
    "    R = [transform_matrix[i][j] for i in range(3) for j in range(3)]\n",
    "\n",
    "    # Create projection matrix (simply use K for now since we're not doing stereo)\n",
    "    P = [\n",
    "        K[0], K[1], K[2], 0,\n",
    "        K[3], K[4], K[5], 0,\n",
    "        K[6], K[7], K[8], 0\n",
    "    ]\n",
    "\n",
    "    # For simplicity, assume no distortion\n",
    "    D = [0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "\n",
    "    return {\n",
    "        'width': width,\n",
    "        'height': height,\n",
    "        'K': K,\n",
    "        'R': R,\n",
    "        'P': P,\n",
    "        'D': D\n",
    "    }\n",
    "\n",
    "def create_camera_info_msg(camera_params, frame_id=\"camera_link\"):\n",
    "    \"\"\"Create a CameraInfo message with the given parameters.\"\"\"\n",
    "    msg = sensor_msgs__msg__CameraInfo(\n",
    "        header={\n",
    "            'frame_id': frame_id,\n",
    "            'stamp': {'sec': int(time.time()), 'nsec': 0}\n",
    "        },\n",
    "        height=camera_params['height'],\n",
    "        width=camera_params['width'],\n",
    "        distortion_model='plumb_bob',\n",
    "        D=camera_params['D'],\n",
    "        K=camera_params['K'],\n",
    "        R=camera_params['R'],\n",
    "        P=camera_params['P'],\n",
    "        binning_x=0,\n",
    "        binning_y=0,\n",
    "        roi={'x_offset': 0, 'y_offset': 0, 'height': 0, 'width': 0, 'do_rectify': False}\n",
    "    )\n",
    "    return msg\n",
    "\n",
    "def write_camera_info_to_bag(\n",
    "    bag_path,\n",
    "    camera_params,\n",
    "    topic_name=\"/camera/camera_info\",\n",
    "    frame_rate=30,\n",
    "    duration_seconds=10,\n",
    "    frame_id=\"camera_link\"\n",
    "):\n",
    "    \"\"\"Write CameraInfo messages to a ROS1 bag file.\"\"\"\n",
    "    bag_path = Path(bag_path)\n",
    "    bag_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    num_msgs = int(frame_rate * duration_seconds)\n",
    "    camera_info_msg = create_camera_info_msg(camera_params, frame_id)\n",
    "\n",
    "    with Writer(bag_path) as writer:\n",
    "        connection = writer.add_connection(\n",
    "            topic_name,\n",
    "            'sensor_msgs/CameraInfo'\n",
    "        )\n",
    "\n",
    "        for i in range(num_msgs):\n",
    "            timestamp = int(time.time() * 1e9)\n",
    "            camera_info_msg['header']['stamp']['sec'] = timestamp // 1_000_000_000\n",
    "            camera_info_msg['header']['stamp']['nsec'] = timestamp % 1_000_000_000\n",
    "            writer.write(connection, timestamp, camera_info_msg)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Get camera parameters from Blender\n",
    "    camera_params = get_blender_camera_info()\n",
    "\n",
    "    # # Write to bag file\n",
    "    # write_camera_info_to_bag(\n",
    "    #     bag_path=\"output/camera_info.bag\",\n",
    "    #     camera_params=camera_params,\n",
    "    #     topic_name=\"/camera/camera_info\",\n",
    "    #     frame_rate=30,\n",
    "    #     duration_seconds=10\n",
    "    # )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rosbags.rosbag1 import Writer\n",
    "from rosbags.typesys.types import sensor_msgs__msg__CameraInfo\n",
    "import numpy as np\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "def calculate_camera_params(\n",
    "    width,                    # Resolution X\n",
    "    height,                   # Resolution Y\n",
    "    focal_length_mm,          # Focal Length from Blender\n",
    "    sensor_width_mm,          # Sensor Width from Blender\n",
    "    camera_position=(0,0,0),  # Camera Position from Transform\n",
    "    camera_rotation=(0,0,0)   # Camera Rotation (in degrees) from Transform\n",
    "):\n",
    "    \"\"\"Calculate camera parameters from manual Blender values.\"\"\"\n",
    "\n",
    "    # Calculate focal length in pixels\n",
    "    focal_length_pixels = (focal_length_mm / sensor_width_mm) * width\n",
    "\n",
    "    # Calculate optical center (assuming centered principal point)\n",
    "    cx = width / 2\n",
    "    cy = height / 2\n",
    "\n",
    "    # Create camera intrinsic matrix K\n",
    "    K = [\n",
    "        focal_length_pixels, 0, cx,\n",
    "        0, focal_length_pixels, cy,\n",
    "        0, 0, 1\n",
    "    ]\n",
    "\n",
    "    # For simplicity, use identity matrix for R if you don't need exact orientation\n",
    "    R = [1, 0, 0,\n",
    "         0, 1, 0,\n",
    "         0, 0, 1]\n",
    "\n",
    "    # Create projection matrix\n",
    "    P = [\n",
    "        K[0], K[1], K[2], 0,\n",
    "        K[3], K[4], K[5], 0,\n",
    "        K[6], K[7], K[8], 0\n",
    "    ]\n",
    "\n",
    "    # Assume no distortion\n",
    "    D = [0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "\n",
    "    return {\n",
    "        'width': width,\n",
    "        'height': height,\n",
    "        'K': K,\n",
    "        'R': R,\n",
    "        'P': P,\n",
    "        'D': D\n",
    "    }\n",
    "\n",
    "def create_camera_info_msg(camera_params, frame_id=\"camera_link\"):\n",
    "    \"\"\"Create a CameraInfo message with the given parameters.\"\"\"\n",
    "    msg = sensor_msgs__msg__CameraInfo(\n",
    "        header={\n",
    "            'frame_id': frame_id,\n",
    "            'stamp': {'sec': int(time.time()), 'nsec': 0}\n",
    "        },\n",
    "        height=camera_params['height'],\n",
    "        width=camera_params['width'],\n",
    "        distortion_model='plumb_bob',\n",
    "        D=camera_params['D'],\n",
    "        K=camera_params['K'],\n",
    "        R=camera_params['R'],\n",
    "        P=camera_params['P'],\n",
    "        binning_x=0,\n",
    "        binning_y=0,\n",
    "        roi={'x_offset': 0, 'y_offset': 0, 'height': 0, 'width': 0, 'do_rectify': False}\n",
    "    )\n",
    "    return msg\n",
    "\n",
    "def write_camera_info_to_bag(\n",
    "    bag_path,\n",
    "    camera_params,\n",
    "    topic_name=\"/camera/camera_info\",\n",
    "    frame_rate=30,\n",
    "    duration_seconds=10,\n",
    "    frame_id=\"camera_link\"\n",
    "):\n",
    "    \"\"\"Write CameraInfo messages to a ROS1 bag file.\"\"\"\n",
    "    bag_path = Path(bag_path)\n",
    "    bag_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    num_msgs = int(frame_rate * duration_seconds)\n",
    "    camera_info_msg = create_camera_info_msg(camera_params, frame_id)\n",
    "\n",
    "    with Writer(bag_path) as writer:\n",
    "        connection = writer.add_connection(\n",
    "            topic_name,\n",
    "            'sensor_msgs/CameraInfo'\n",
    "        )\n",
    "\n",
    "        for i in range(num_msgs):\n",
    "            timestamp = int(time.time() * 1e9)\n",
    "            camera_info_msg['header']['stamp']['sec'] = timestamp // 1_000_000_000\n",
    "            camera_info_msg['header']['stamp']['nsec'] = timestamp % 1_000_000_000\n",
    "            writer.write(connection, timestamp, camera_info_msg)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example values - Replace these with your actual values from Blender\n",
    "    camera_params = calculate_camera_params(\n",
    "        width=1280,              # From Output Properties > Resolution X\n",
    "        height=720,             # From Output Properties > Resolution Y\n",
    "        focal_length_mm=88.19,      # From Camera Properties > Focal Length\n",
    "        sensor_width_mm=36,      # From Camera Properties > Sensor Width\n",
    "        camera_position=(0,0,2), # From Transform panel\n",
    "        camera_rotation=(0,0,0)  # From Transform panel\n",
    "    )\n",
    "\n",
    "    # Write to bag file\n",
    "    write_camera_info_to_bag(\n",
    "        bag_path=\"output/camera_info.bag\",\n",
    "        camera_params=camera_params,\n",
    "        frame_rate=30,\n",
    "        duration_seconds=10\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mr-2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
